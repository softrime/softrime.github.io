<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-US"><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://localhost:4000/home/softrime/Work/Blog/softrime.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/home/softrime/Work/Blog/softrime.github.io/" rel="alternate" type="text/html" hreflang="en-US" /><updated>2019-10-10T12:52:16+02:00</updated><id>http://localhost:4000/home/softrime/Work/Blog/softrime.github.io/feed.xml</id><title type="html"> </title><subtitle>providing documentation and blog post pages. Stay hungry, stay recording.
</subtitle><entry><title type="html">Interspeech 2019 Voice Conversion Paper Review</title><link href="http://localhost:4000/home/softrime/Work/Blog/softrime.github.io/blog/2019/10/10/interspeech-2019-review/" rel="alternate" type="text/html" title="Interspeech 2019 Voice Conversion Paper Review" /><published>2019-10-10T04:11:09+02:00</published><updated>2019-10-10T04:11:09+02:00</updated><id>http://localhost:4000/home/softrime/Work/Blog/softrime.github.io/blog/2019/10/10/interspeech-2019-review</id><content type="html" xml:base="http://localhost:4000/home/softrime/Work/Blog/softrime.github.io/blog/2019/10/10/interspeech-2019-review/">&lt;blockquote&gt;
  &lt;p&gt;For Interspeech 2019, this year there are two sessions about Voice Conversion(VC). For my personal interests, I would mostly review VC-related papers in session &lt;strong&gt;’
Neural Techniques for Voice Conversion and Waveform Generation’&lt;/strong&gt;. (Still work in progress)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;!--more--&gt;

&lt;ul class=&quot;table-of-content&quot; id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#non-parallel-voice-conversion-using-weighted-generative-adversarial-networks&quot; id=&quot;markdown-toc-non-parallel-voice-conversion-using-weighted-generative-adversarial-networks&quot;&gt;Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;non-parallel-voice-conversion-using-weighted-generative-adversarial-networks&quot;&gt;Non-Parallel Voice Conversion Using Weighted Generative Adversarial Networks&lt;/h4&gt;

&lt;p&gt;This paper modifies loss function in StarGAN. In detail, authors add a weight factor on the adversarial loss when update Generators, which means &lt;script type=&quot;math/tex&quot;&gt;w_iD(G(x_i, c))&lt;/script&gt; . The weight can be considered as the fake confidence for a sample. It reduces the loss of samples which is considered as fake with a high confidence by Discriminator.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;em_2=2&lt;/script&gt;

&lt;p&gt;\begin{equation} f(x)=3x+7,\sigma \end{equation}&lt;/p&gt;

&lt;p&gt;asd&lt;/p&gt;

&lt;p&gt;\( w_i = 2^2 \)&lt;/p&gt;</content><author><name>softrime</name></author><summary type="html">For Interspeech 2019, this year there are two sessions about Voice Conversion(VC). For my personal interests, I would mostly review VC-related papers in session ’ Neural Techniques for Voice Conversion and Waveform Generation’. (Still work in progress)</summary></entry></feed>